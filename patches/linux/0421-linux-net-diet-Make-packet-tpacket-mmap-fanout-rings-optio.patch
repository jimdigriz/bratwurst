diff -u -r -N linux-4.0.4.orig/net/packet/af_packet.c linux-4.0.4/net/packet/af_packet.c
--- linux-4.0.4.orig/net/packet/af_packet.c	2015-06-07 18:02:32.817220170 +0100
+++ linux-4.0.4/net/packet/af_packet.c	2015-06-07 18:03:47.665217615 +0100
@@ -158,6 +158,8 @@
 	unsigned char	mr_address[MAX_ADDR_LEN];
 };
 
+#ifdef CONFIG_PACKET_MMAP
+
 union tpacket_uhdr {
 	struct tpacket_hdr  *h1;
 	struct tpacket2_hdr *h2;
@@ -165,8 +167,6 @@
 	void *raw;
 };
 
-static int packet_set_ring(struct sock *sk, union tpacket_req_u *req_u,
-		int closing, int tx_ring);
 
 #define V3_ALIGNMENT	(8)
 
@@ -213,6 +213,9 @@
 		struct tpacket3_hdr *);
 static void prb_fill_vlan_info(struct tpacket_kbdq_core *,
 		struct tpacket3_hdr *);
+
+#endif
+
 static void packet_flush_mclist(struct sock *sk);
 
 struct packet_skb_cb {
@@ -378,6 +381,8 @@
 		__unregister_prot_hook(sk, sync);
 }
 
+#ifdef CONFIG_PACKET_MMAP
+
 static inline struct page * __pure pgv_to_page(void *addr)
 {
 	if (is_vmalloc_addr(addr))
@@ -1212,6 +1217,8 @@
 	return refcnt;
 }
 
+#endif
+
 static int packet_alloc_pending(struct packet_sock *po)
 {
 	po->rx_ring.pending_refcnt = NULL;
@@ -1228,6 +1235,7 @@
 	free_percpu(po->tx_ring.pending_refcnt);
 }
 
+#ifdef CONFIG_PACKET_MMAP
 static bool packet_rcv_has_room(struct packet_sock *po, struct sk_buff *skb)
 {
 	struct sock *sk = &po->sk;
@@ -1251,6 +1259,8 @@
 	return has_room;
 }
 
+#endif
+
 static void packet_sock_destruct(struct sock *sk)
 {
 	skb_queue_purge(&sk->sk_error_queue);
@@ -1266,6 +1276,8 @@
 	sk_refcnt_debug_dec(sk);
 }
 
+#ifdef CONFIG_PACKET_MMAP
+
 static int fanout_rr_next(struct packet_fanout *f, unsigned int num)
 {
 	int x = atomic_read(&f->rr_cur) + 1;
@@ -1532,6 +1544,12 @@
 	mutex_unlock(&fanout_mutex);
 }
 
+#else
+static void __fanout_unlink(struct sock *sk, struct packet_sock *po) {}
+static void __fanout_link(struct sock *sk, struct packet_sock *po) {}
+static void fanout_release(struct sock *sk) {}
+#endif
+
 static const struct proto_ops packet_ops;
 
 static const struct proto_ops packet_ops_spkt;
@@ -1869,6 +1887,11 @@
 	return 0;
 }
 
+#ifdef CONFIG_PACKET_MMAP
+
+static int packet_set_ring(struct sock *sk, union tpacket_req_u *req_u,
+		int closing, int tx_ring);
+
 static int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,
 		       struct packet_type *pt, struct net_device *orig_dev)
 {
@@ -2106,18 +2129,6 @@
 	sock_wfree(skb);
 }
 
-static bool ll_header_truncated(const struct net_device *dev, int len)
-{
-	/* net device doesn't like empty head */
-	if (unlikely(len <= dev->hard_header_len)) {
-		net_warn_ratelimited("%s: packet size is too short (%d <= %d)\n",
-				     current->comm, len, dev->hard_header_len);
-		return true;
-	}
-
-	return false;
-}
-
 static int tpacket_fill_skb(struct packet_sock *po, struct sk_buff *skb,
 		void *frame, struct net_device *dev, int size_max,
 		__be16 proto, unsigned char *addr, int hlen)
@@ -2379,6 +2390,47 @@
 	return err;
 }
 
+static inline bool use_tpacket(struct packet_sock *po)
+{
+	return po->tx_ring.pg_vec;
+}
+
+static void tpacket_release(struct sock *sk, struct packet_sock *po)
+{
+	union tpacket_req_u req_u;
+
+	if (po->rx_ring.pg_vec) {
+		memset(&req_u, 0, sizeof(req_u));
+		packet_set_ring(sk, &req_u, 1, 0);
+	}
+
+	if (po->tx_ring.pg_vec) {
+		memset(&req_u, 0, sizeof(req_u));
+		packet_set_ring(sk, &req_u, 1, 1);
+	}
+}
+
+#else
+static inline bool use_tpacket(struct packet_sock *po) { return false; }
+static inline void tpacket_release(struct sock *sk, struct packet_sock *po) {}
+static inline int tpacket_snd(struct packet_sock *po, struct msghdr *msg) { return 0; }
+static inline int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,
+			      struct packet_type *pt, struct net_device *orig_dev)
+{ return 0; }
+#endif
+
+static bool ll_header_truncated(const struct net_device *dev, int len)
+{
+	/* net device doesn't like empty head */
+	if (unlikely(len <= dev->hard_header_len)) {
+		net_warn_ratelimited("%s: packet size is too short (%d <= %d)\n",
+				     current->comm, len, dev->hard_header_len);
+		return true;
+	}
+
+	return false;
+}
+
 static struct sk_buff *packet_alloc_skb(struct sock *sk, size_t prepad,
 				        size_t reserve, size_t len,
 				        size_t linear, int noblock,
@@ -2609,7 +2661,7 @@
 	struct sock *sk = sock->sk;
 	struct packet_sock *po = pkt_sk(sk);
 
-	if (po->tx_ring.pg_vec)
+	if (use_tpacket(po))
 		return tpacket_snd(po, msg);
 	else
 		return packet_snd(sock, msg, len);
@@ -2625,7 +2677,6 @@
 	struct sock *sk = sock->sk;
 	struct packet_sock *po;
 	struct net *net;
-	union tpacket_req_u req_u;
 
 	if (!sk)
 		return 0;
@@ -2653,15 +2704,7 @@
 
 	packet_flush_mclist(sk);
 
-	if (po->rx_ring.pg_vec) {
-		memset(&req_u, 0, sizeof(req_u));
-		packet_set_ring(sk, &req_u, 1, 0);
-	}
-
-	if (po->tx_ring.pg_vec) {
-		memset(&req_u, 0, sizeof(req_u));
-		packet_set_ring(sk, &req_u, 1, 1);
-	}
+	tpacket_release(sk, po);
 
 	fanout_release(sk);
 
@@ -3243,7 +3286,7 @@
 packet_setsockopt(struct socket *sock, int level, int optname, char __user *optval, unsigned int optlen)
 {
 	struct sock *sk = sock->sk;
-	struct packet_sock *po = pkt_sk(sk);
+	struct packet_sock *po __maybe_unused = pkt_sk(sk);
 	int ret;
 
 	if (level != SOL_PACKET)
@@ -3271,6 +3314,7 @@
 		return ret;
 	}
 
+#ifdef CONFIG_PACKET_MMAP
 	case PACKET_RX_RING:
 	case PACKET_TX_RING:
 	{
@@ -3354,6 +3398,7 @@
 		po->tp_loss = !!val;
 		return 0;
 	}
+#endif
 	case PACKET_AUXDATA:
 	{
 		int val;
@@ -3406,6 +3451,7 @@
 		po->tp_tstamp = val;
 		return 0;
 	}
+#ifdef CONFIG_PACKET_MMAP
 	case PACKET_FANOUT:
 	{
 		int val;
@@ -3430,6 +3476,7 @@
 		po->tp_tx_has_off = !!val;
 		return 0;
 	}
+#endif
 	case PACKET_QDISC_BYPASS:
 	{
 		int val;
@@ -3655,6 +3702,7 @@
 	return 0;
 }
 
+#ifdef CONFIG_PACKET_MMAP
 static unsigned int packet_poll(struct file *file, struct socket *sock,
 				poll_table *wait)
 {
@@ -3899,7 +3947,7 @@
 		swap(rb->pg_vec_len, req->tp_block_nr);
 
 		rb->pg_vec_pages = req->tp_block_size/PAGE_SIZE;
-		po->prot_hook.func = (po->rx_ring.pg_vec) ?
+		po->prot_hook.func = use_tpacket(po) ?
 						tpacket_rcv : packet_rcv;
 		skb_queue_purge(rb_queue);
 		if (atomic_read(&po->mapped))
@@ -3988,6 +4036,10 @@
 	mutex_unlock(&po->pg_vec_lock);
 	return err;
 }
+#else
+#define packet_mmap sock_no_mmap
+#define packet_poll datagram_poll
+#endif
 
 static const struct proto_ops packet_ops_spkt = {
 	.family =	PF_PACKET,
Binary files linux-4.0.4.orig/net/packet/.af_packet.c.swp and linux-4.0.4/net/packet/.af_packet.c.swp differ
diff -u -r -N linux-4.0.4.orig/net/packet/Kconfig linux-4.0.4/net/packet/Kconfig
--- linux-4.0.4.orig/net/packet/Kconfig	2015-06-07 18:02:32.817220170 +0100
+++ linux-4.0.4/net/packet/Kconfig	2015-06-07 17:56:05.989233376 +0100
@@ -22,3 +22,11 @@
 	---help---
 	  Support for PF_PACKET sockets monitoring interface used by the ss tool.
 	  If unsure, say Y.
+
+config PACKET_MMAP
+	bool "Enable packet mmap/ring support"
+	depends on PACKET
+	default y
+	---help---
+	  Enable support to mmap the packet data zero copy. This is useful for
+	  highspeed packet interceptors.
